{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業\n",
    "* 在精簡深度學習的方式上 : 卷積類神經 (CNN) 採用像素遠近，而遞歸類神經 (RNN) 採用著則是時間遠近\n",
    "* 那麼，既然有著類似的設計精神，兩者是否有可能互換應用呢?\n",
    "\n",
    "不能。\n",
    "CNN訓練固定像素的圖像。RNN可以處理不定長的輸入，得到一定的輸出。\n",
    "CNN只能響應預先設定的信號長度。RNN的響應長度是可以學習出來的。\n",
    "CNN對特徵的響應是線性的。RNN在這個遞進方向上是非線性響應的。\n",
    "CNN專門解決圖像問題。RNN專門解決時間序列問題。\n",
    "CNN側重空間映射，RNN遞歸型網路。\n",
    "CNN卷積擅長從局部特徵逼近整體特徵，RNN擅長對付時間序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷積神經網路(CNN)\n",
    "#### 為什麼使用CNN?\n",
    "* 密集神經網路適合用來處理單色、小尺寸的圖片辨識，遇到大尺寸、彩色圖片，特徵值的量會增加更多，權重參數也會暴增。當我們給他的訓練資料沒這麼多時，訓練就非常可能發生過度配適(overfitiing)的問題。\n",
    "* CNN可以讓我們在有限的資料數量下，降低神經網路的權重數量，且保持一定的學習能力。\n",
    "#### 卷積神經網路(CNN)的基本架構\n",
    "* 圖片 → 卷積層 → 池化層 → 密集層 → 輸出層\n",
    "* 卷積層和池化層主要做圖片的特徵萃取，也就是從原始圖片中萃取出足以辨識圖片內容的特徵。\n",
    "#### 卷積層(Convolution Layer)的運算\n",
    "* 利用 $nxn$ 大小的過濾器(Filters)，或稱卷積核(Convolution kernel)將圖片各區域掃過一遍，萃取輸入圖片的特徵，達到減少特徵量的目的。\n",
    "* 卷積層和池化層主要做圖片的特徵萃取，也就是從原始圖片中萃取出足以辨識圖片內容的特徵。\n",
    "#### 卷積層架購\n",
    "* 圖片 → (過濾器萃取特徵，過濾器做「輸入x權重」的加總) → 特徵圖 \n",
    "* 特徵圖 → 加上偏值 → 傳入ReLU激活函數 → 處理後的特徵圖\n",
    "#### 池化層(Pooling Layer)的運算\n",
    "* 池化層皆在卷積層的後面，負責對卷積層輸出的特徵圖做\"重點挑選\"，繼續縮小特徵值的尺寸。將特徵圖分割成多個區域後，利用最大池化法和平均池化法進行重點挑選。\n",
    "* 最大池化法：取各區域的最大值。\n",
    "* 平均池化法：取各區域的平均值。\n",
    "#### 池化層 → 密集層(Dense Layer)的運算\n",
    "* 池化層輸出的特徵圖(矩陣形式)轉換成向量的形式，再傳入密集層。\n",
    "#### 填補(Padding)與步長(Stride)的概念\n",
    "* 填補：不希望輸入圖片被萃取的太小張所採取的做法。\n",
    "* 補零法(CNN常用)：在卷積運算前先加大輸入圖片的尺寸，具體的做法是在輸入圖片的周圍補上像素值0。\n",
    "* 步長：一般步長設為1，如果輸入圖片的尺寸很大，為了加速掃過圖片，有時會將步長設為2。選擇的步長不同，特徵圖的執行結果與尺寸也會不同。加大步長會使算出來的特徵圖尺寸變小。\n",
    "* 特徵圖尺寸：輸入圖片的尺寸是$I_h$ x $I_w$，過濾器的尺寸是$F_h$ x $F_w$，填補的寬度是 $D$，步長值是 $S$，可以用以下公式算出輸出圖片的高度$O_h$與寬度$O_w$\n",
    "* $O_h$ = ($I_h$ - $F_h$ + 2$D$)/$S$  + 1\n",
    "* $O_w$ = ($I_w$ - $F_w$ + 2$D$)/$S$  + 1\n",
    "#### 訓練CNN網路的方法\n",
    "* 前向傳播運算。\n",
    "* 利用損失函數、反向傳播、梯度下降...等方法「可讓總誤差(損失函數)的值極小化」的最佳權重配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 循環神經網路(RNN)\n",
    "* 擅長處理序列資料(Sequence Data)的神經網路，運用的領域包括自然語言處理、與時間相關的股價預測...等。\n",
    "\n",
    "#### RNN的基本概要\n",
    "* RNN 跟密集神經網路最明顯的差異，就是中間層具備了「循環」機制，又稱為「回饋(Feedback)」，中間層處裡完第0個時間點(t=0)的輸入所得到的輸出，會回饋給中間層再度成為輸入，與下一個時間點(t=1)的輸入一起處理，運算完成後的輸出值再度回饋給中間層。\n",
    "* 也就是說，各時間點(t)的中間值「輸出值」會一直循環成為下一個時間點(t+1)的中間層的「輸入值」會一直循環成為下一個時間點(t+1)的中間層「輸入值」，最終得到的輸出其實是融合每一個時間點(t)的資料所得到的結果。\n",
    "* 正因為循環特性，RNN可能發生「梯度消失」類似的問題。舊時間點的資料雖然被循環不斷拿來使用，但如果時間點一多，例如有800個，中間層需要循環學習多達800個時間點的資料，可能發生「記憶消失」的問題。\n",
    "\n",
    "#### LSTM(長短期記憶神經網路)\n",
    "* LSTM(Long short-term memory, 長短期記憶神經網路)是由RNN改良而來，可以克服RNN難以保持長期記憶的問題。LSTM是「長期」記憶或「短期」記憶都可以保留下來。差別在於LSTM的中間層換成了稱為「LSTM區塊」的設計。\n",
    "* LSTM區塊內部的結構就類似電路，以稱為「閘門(gate)」的功能判斷過去時間點的資料「可以忘記」或「不可以忘記」。\n",
    "* 閘門種類有「遺忘閘(Forget gate)」、「輸入閘(Input gate)」、「輸出閘(Output gate)」等等。\n",
    "1. 遺忘閘：用來決定哪些資料可以忘記。\n",
    "2. 輸入閘：用來決定哪些新的資料是否要加入到記憶單元。\n",
    "3. 輸出閘：用來決定哪些資料需要從記憶單元中取出來繼續用，也就是下一個時間點的輸入。\n",
    "\n",
    "#### LSTM的改良版-GRU\n",
    "* 由於LSTM的結構有點複雜，因此就有改良版GRU出現。\n",
    "* 為了精簡結構，GRU把LSTM的輸入閘與遺忘閘合併成「更新閘(Update gate)」，而且少了記憶單元與輸出閘，但增加了「還原閘(Reset gate)」，整體來說比LSTM擁有更好的效能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 參考資訊：\n",
    "* 深度學習：常見算法(CNN,RNN)比較： https://pcnow.cc/p/JONBZ368bd.html\n",
    "* python 深度學習基礎養成, 作者： 我妻幸長, 譯者： 吳嘉芳, 出版社：旗標, 出版日期：2020/07/07。                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
